{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Script para dividir os datasets em treino e teste\n",
        "Para cada um dos datasets divide-os em treino e teste e, o set de treino é dividido na proporção 80/20 para treino e validação pelo script de treinamento."
      ],
      "metadata": {
        "id": "EhYCrQnjFTJb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AV6PlfrGFJCu",
        "outputId": "6419883d-4fb1-46b7-b012-ee7ff3d58ce5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import pickle\n",
        "import gc\n",
        "\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "XHqwj24qFl_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(train_prop=0.5):\n",
        "\n",
        "\n",
        "  base_dir = '/content/gdrive/Shareddrives/TCC - S09/Notebooks/resized data/'\n",
        "\n",
        "  # Lista de datasets\n",
        "  DATASETS = [\n",
        "    'AA_2014_2014-03-27_09-10-00_12Hz',\n",
        "    'AA_2015_2015-03-05_10-35-00_12Hz',\n",
        "    'AA_2015_2015-05-15_09-00-00_12Hz',\n",
        "    'YS_2017_2017-05-13_05-00-00_10Hz',\n",
        "    'BS_2011_2011-10-01_16-18-00_15Hz',\n",
        "    'BS_2011_2011-10-04_11-38-00_12Hz',\n",
        "    'BS_2011_2011-10-04_13-07-00_12Hz',\n",
        "    'BS_2011_2011-10-04_15-30-00_12Hz',\n",
        "    'BS_2013_2013-09-22_13-00-01_10Hz',\n",
        "    'BS_2013_2013-09-25_12-15-01_12Hz',\n",
        "    'BS_2013_2013-09-30_10-20-01_12Hz',\n",
        "    'LJ_2018_2018-01-03_09-39-38_10Hz'\n",
        "  ]\n",
        "\n",
        "  for dataset in DATASETS:\n",
        "    with open(base_dir + dataset + '_2058_224.pkl', 'rb') as f:\n",
        "      record = pickle.load(f)\n",
        "\n",
        "    print('----------------------')\n",
        "    print(f'Dataset: {dataset} \\n')\n",
        "\n",
        "    # Split data into training/test set (<train_prop>/1-<train_prop>)\n",
        "    train_size = int(train_prop * len(record))\n",
        "    test_size = len(record) - train_size\n",
        "    train_set, test_set = torch.utils.data.random_split(record, [train_size, test_size])\n",
        "\n",
        "    del record\n",
        "    gc.collect()\n",
        "\n",
        "    # Salvando os novos sets\n",
        "    with open(f'/content/gdrive/Shareddrives/TCC - S09/Notebooks/splitted data/train/{dataset}_2058_224.pkl', 'wb') as f:\n",
        "      pickle.dump(train_set, f)\n",
        "\n",
        "    \n",
        "    with open(f'/content/gdrive/Shareddrives/TCC - S09/Notebooks/splitted data/test/{dataset}_2058_224.pkl', 'wb') as f:\n",
        "      pickle.dump(test_set, f)\n",
        "\n",
        "\n",
        "    del train_set\n",
        "    del test_set\n",
        "    gc.collect()"
      ],
      "metadata": {
        "id": "60Fj0PWgF5HU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kIDOWkTIp_Y",
        "outputId": "f0e4752c-b3f6-4c96-9484-98bafb25d055"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------\n",
            "Dataset: AA_2014_2014-03-27_09-10-00_12Hz \n",
            "\n",
            "----------------------\n",
            "Dataset: AA_2015_2015-03-05_10-35-00_12Hz \n",
            "\n",
            "----------------------\n",
            "Dataset: AA_2015_2015-05-15_09-00-00_12Hz \n",
            "\n",
            "----------------------\n",
            "Dataset: YS_2017_2017-05-13_05-00-00_10Hz \n",
            "\n",
            "----------------------\n",
            "Dataset: BS_2011_2011-10-01_16-18-00_15Hz \n",
            "\n",
            "----------------------\n",
            "Dataset: BS_2011_2011-10-04_11-38-00_12Hz \n",
            "\n",
            "----------------------\n",
            "Dataset: BS_2011_2011-10-04_13-07-00_12Hz \n",
            "\n",
            "----------------------\n",
            "Dataset: BS_2011_2011-10-04_15-30-00_12Hz \n",
            "\n",
            "----------------------\n",
            "Dataset: BS_2013_2013-09-22_13-00-01_10Hz \n",
            "\n",
            "----------------------\n",
            "Dataset: BS_2013_2013-09-25_12-15-01_12Hz \n",
            "\n",
            "----------------------\n",
            "Dataset: BS_2013_2013-09-30_10-20-01_12Hz \n",
            "\n",
            "----------------------\n",
            "Dataset: LJ_2018_2018-01-03_09-39-38_10Hz \n",
            "\n"
          ]
        }
      ]
    }
  ]
}